# -*- coding: utf-8 -*-
"""Another copy of CS110_Project6_Part2ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WrXqr-IKizDopl_tCXmDgUyQ7onpQ7ho

# Project 6: Advanced Text Analysis with SpaCy

### Overview

In this project, we will enhance our text analysis techniques by applying proper data pre-processing to extract more meaningful information from literary texts. We'll continue working with the first two chapters of "Pride and Prejudice" but will implement advanced text cleaning methods using the SpaCy library to obtain more insightful word frequency results.

### Project Objectives

*   Apply proper text pre-processing techniques to extract
meaningful words

*   Use SpaCy to clean and normalize text data
*   Identify the 15 most frequently used meaningful words in a text

*   Analyze how pre-processing affects text analysis results
*   Apply the same techniques to a text of your choice

### Part 2: Text Analysis of your choice with pre-processing

For the second part of the project, you will:

* Choose another text that interests you (a novel, article, speech, etc.) (You should make another copy of this colab file and change the name to CS110_Project6_Part2.ipynb)
* Produce 10 to 15 most frequrently used words without text preprocessing
* Apply the same pre-processing steps using SpaCy
* Identify the 15 most frequently used meaningful words
* Write a 1-2 paragraph analysis of what these words reveal about the text's content and themes, and why we need text pre-processing now that you have worked on at least two sets of text
"""

text = """
Four score and seven years ago our fathers brought forth on this continent, a new nation,
conceived in Liberty, and dedicated to the proposition that all men are created equal.

Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated,
can long endure. We are met on a great battlefield of that war. We have come to dedicate a portion of that field,
as a final resting place for those who here gave their lives that that nation might live. It is altogether fitting
and proper that we should do this.

But, in a larger sense, we cannot dedicate—we cannot consecrate—we cannot hallow—this ground. The brave men,
living and dead, who struggled here, have consecrated it far above our poor power to add or detract.
The world will little note, nor long remember what we say here, but it can never forget what they did here.
It is for us the living, rather, to be dedicated here to the unfinished work which they who fought here have thus
far so nobly advanced. It is rather for us to be here dedicated to the great task remaining before us—that from these
honored dead we take increased devotion to that cause for which they gave the last full measure of devotion—that we
here highly resolve that these dead shall not have died in vain—that this nation, under God, shall have a new birth
of freedom—and that government of the people, by the people, for the people, shall not perish from the earth.
"""
from collections import Counter
import re

# Tokenize using regular expressions
words = re.findall(r'\w+', text.lower())
word_counts = Counter(words)

# Print top 15 words without preprocessing
print("Top 15 words without preprocessing:")
print(word_counts.most_common(15))

# importing spacy
import spacy

# Load English NLP model
nlp = spacy.load("en_core_web_sm")
doc = nlp(text)

# Pre-process: lemmatize, remove stopwords, punctuation, and non-alpha tokens
processed_words = [
    token.lemma_.lower() for token in doc
    if token.is_alpha and not token.is_stop
]

# Count and print top 15 processed words
processed_word_counts = Counter(processed_words)
print("Top 15 words after SpaCy preprocessing:")
print(processed_word_counts.most_common(15))

"""Before proccesinbg the most frequent words are function words such as: "the","we", "That".these words dont give the meaning or theme of the content i chose that was Abrahm Lincolns speech. After preprossing gthe words that became most frequent were: "nation", "freedom", "devotion", "people". These words actually give meaninbg and a gist of that the main idea and a clearer explanaton defining the speech.

In my analisis of this project i have learned preproccesing is important and helps filter out common words that dont carry a meaning and helps provide words that give a clearer insight to what the text is really about.

### Deliverable

Download both notebooks by clicking on the File Menu (below the name of the file), Download > Download .ipynb and submit them.

1. CS110_Project6_Part1.ipynb with all TODO tasks done
2. CS110_Project6_Part2.ipynb with the write-up after producing 15 most frequently used meaningful words from a text of your choice
"""
